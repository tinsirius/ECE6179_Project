{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb176c99-fa2b-4111-b850-dc7d93921d7a",
   "metadata": {},
   "source": [
    "# Install pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a49a3-4ac7-48b4-981f-6a74d5f206aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e5bee-96b9-46d4-b7a5-9619a33f7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249600e-034b-4de2-9d98-196f036cf9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d0c25-6bd7-4cfc-8ac0-c9d55457da76",
   "metadata": {},
   "source": [
    "# Pretrained models\n",
    "\n",
    "Download one of the official pretrained models with:\n",
    "\n",
    "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
    "\n",
    "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c84c82-e451-4b01-8f85-5ca12ae8fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./scripts/download_pix2pix_model.sh day2night"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78baf7a1-62e6-457e-966c-b12e1cdfbb5e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa967b-81eb-4250-86f2-a4170b7e0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b72c1-37c5-4432-bf0a-ff4620db2cbd",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd50fef-4dfd-4797-8f0c-ee5a33e7caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy.io.wavfile as wavfile\n",
    "import scipy\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231708a4-dc7a-456b-9635-e35a5ba9b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def audio_to_spectrogram(filename, n_fft=2048):\n",
    "#     waveform, sample_rate = torchaudio.load(filename, normalize=True)\n",
    "    \n",
    "#     melspec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "#         sample_rate=sample_rate,\n",
    "#         n_fft=n_fft\n",
    "#     )\n",
    "    \n",
    "#     waveform = torch.mean(waveform, 0)\n",
    "    \n",
    "#     spectro = melspec_transform(waveform)\n",
    "#     # spectro = librosa.power_to_db(spectro)\n",
    "#     # plt.imshow(spectro)\n",
    "    \n",
    "#     return spectro, sample_rate\n",
    "    \n",
    "# def spectrogram_to_audio(spectro, n_fft=2048, sample_rate=44100):\n",
    "#     inv_melspec_transform = torchaudio.transforms.InverseMelScale(\n",
    "#         sample_rate=sample_rate, \n",
    "#         n_stft=int(n_fft/2 + 1)\n",
    "#     )\n",
    "#     spectro = inv_melspec_transform(spectro)\n",
    "    \n",
    "#     grifflim_transform = torchaudio.transforms.GriffinLim(n_fft=n_fft)\n",
    "#     audio = grifflim_transform(spectro)\n",
    "\n",
    "#     torchaudio.save('data/attenborough/our_planet_1_4_NEW.wav', audio, sample_rate)\n",
    "\n",
    "def waveform_to_spectrogram(filename):\n",
    "    waveform, sample_rate = librosa.load(filename)\n",
    "    \n",
    "    D = np.abs(librosa.stft(waveform))**2\n",
    "    spectro = librosa.feature.melspectrogram(\n",
    "        y=waveform, \n",
    "        sr=sample_rate, \n",
    "        S=D\n",
    "    )\n",
    "    \n",
    "    return spectro, sample_rate\n",
    "\n",
    "\n",
    "def spectrogram_to_audio(spectro, filename, sample_rate=44100):\n",
    "    waveform = librosa.feature.inverse.mel_to_audio(spectro)\n",
    "    \n",
    "    # Conver to tensor so we can save using torchaudio\n",
    "    waveform = np.reshape(waveform, (1, -1))\n",
    "    waveform = torch.from_numpy(waveform)\n",
    "    \n",
    "    torchaudio.save(filename, waveform, sample_rate)\n",
    "    \n",
    "    \n",
    "def spectrogram_to_image(spectro, filename, img_size=(128,128)):\n",
    "    # Convert to decibel scale\n",
    "    spectro_db = librosa.power_to_db(spectro)\n",
    "    spectro_db = cv2.resize(spectro_db, dsize=img_size)\n",
    "    \n",
    "    # Rescale pixel values to be between 0 and 255\n",
    "    spectro_db = spectro_db - np.min(spectro_db)\n",
    "    spectro_db = spectro_db * 255.0 / np.max(spectro_db)\n",
    "\n",
    "    # plt.imshow(spectro_db)\n",
    "    cv2.imwrite(filename, spectro_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15307dee-7b82-444c-a2f6-c54cb03085c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = 'data/attenborough'\n",
    "dir_output = 'data/gtts'\n",
    "\n",
    "\n",
    "# # Convert all files into .wav format\n",
    "# def convert_to_wav(dir_name):\n",
    "#     TOTAL_FILES = len(os.listdir(dir_name))\n",
    "#     for i, filename in enumerate(os.scandir(dir_name)):\n",
    "#         fn = os.path.splitext(filename)[0]\n",
    "#         fn = filename.path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "#         sound = AudioSegment.from_mp3(filename.path)\n",
    "#         sound.export(dir_name + \"_wav/\" + fn + \".wav\", format=\"wav\")\n",
    "\n",
    "#         if (i + 1) % 100 == 0:\n",
    "#             print(\"Converted: \", i + 1, \"/\", TOTAL_FILES, \" files\")\n",
    "\n",
    "\n",
    "# convert_to_wav(dir_input)\n",
    "# convert_to_wav(dir_output)\n",
    "\n",
    "\n",
    "# Convert audio files to spectrogram\n",
    "def wav_to_spectro(dir_name):\n",
    "    TOTAL_FILES = len(os.listdir(dir_name))\n",
    "    for i, filename in enumerate(os.scandir(dir_name)):\n",
    "        fn = os.path.splitext(filename)[0]\n",
    "        fn = filename.path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        spectro, sample_rate = waveform_to_spectrogram(filename.path)\n",
    "        spectrogram_to_image(spectro, dir_name + \"_spectro/\" + fn + \".png\")\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"Converted: \", i + 1, \"/\", TOTAL_FILES, \" files\")\n",
    "\n",
    "\n",
    "wav_to_spectro(dir_input)\n",
    "wav_to_spectro(dir_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
